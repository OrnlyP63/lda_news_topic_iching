{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = pd.read_csv('content.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Update for 2021Things may be getting back to '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I have uploaded some Imperial China era  chart...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Denis Mair has very generously given permissio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dear all,At last, here is something I promised...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Greetings All,    I have  posted a complete ex...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content\n",
       "0  Update for 2021Things may be getting back to '...\n",
       "1  I have uploaded some Imperial China era  chart...\n",
       "2  Denis Mair has very generously given permissio...\n",
       "3  Dear all,At last, here is something I promised...\n",
       "4  Greetings All,    I have  posted a complete ex..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Update for 2021Things may be getting back to 'normal' to some extent, but it would be a shame not to keep these gatherings going. 'Normal' seems to be a way off yet for most of us, doesn’t it? Let's keep on meeting -  every other week, on Thursdays (starting on the January 7th). As always, the live gatherings are open to both Change Circle and WikiWing members, but the recordings will only be available inside Change Circle.~~~~~~~~Since we need connection now more than ever - to Yi and to one another - Clarity will be hosting some extra weekly  fortnightly (every-other-week-ly) video chatsWhat it isWeekly Fortnightly, hour-long video chats about Yi and readings.(And occasionally about something Yeekier, such as nuclear hexagrams.)Who it's forNormally meetings like this are just for Change Circle members, but these are for everyone in Change Circle or WikiWing. That way we limit it to people who are genuinely interested in the Yi (probably a good idea in these days of 'Zoombombing') but cost won't be a barrier.WhenMondays Thursdays at 6pm UK time. Click here to see what that is in your own timezone.I don't know how long the calls will continue for, but at least until the end of April they're too good to stop yet.WhereZoom video chat. A month ago I'd have needed to explain what that is... probably not so much now, right? I've been using it for classes since before they were famous  ; it works beautifully and is nice and easy to use.I'll be emailing the room link round to Change Circle and WikiWing members right away.How to share a readingI do much better with readings if I have a chance to think about them for a while and let them sink in. I don't think I'm alone in that, so let's share readings in advance of the calls. Here's how:If you are a member of Change Circle or WikiWing, and have a reading you'd like to share...and if and only if you are definitely coming to the next call...then please post a link to the reading on this thread.We don't want this thread to fill up with reading interpretations, so please just post a link to your reading thread in Shared Readings or Reading Circle.(Change Circle people - that means you can link to a reading in 'Reading Circle' and know it won't be shared beyond CC plus those who turn up to the call.)Last edited: Jan 4, 2021\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents['content'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=[]\n",
    "for doc in documents.content:\n",
    "    text=re.sub('[^a-zA-z]',' ', doc)\n",
    "    text=text.lower()\n",
    "    text=text.split()\n",
    "    text=[PorterStemmer().stem(word) for word in text if not word in stop]\n",
    "    text=' '.join(text)\n",
    "    corpus.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents['clean_content'] = corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>clean_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Update for 2021Things may be getting back to '...</td>\n",
       "      <td>updat thing may get back normal extent would s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I have uploaded some Imperial China era  chart...</td>\n",
       "      <td>upload imperi china era chart contempl ching w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Denis Mair has very generously given permissio...</td>\n",
       "      <td>deni mair gener given permiss host yije articl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dear all,At last, here is something I promised...</td>\n",
       "      <td>dear last someth promis long time ago seem fin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Greetings All,    I have  posted a complete ex...</td>\n",
       "      <td>greet post complet explan king wen sequenc chi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>Joseph Yu, co-author of the 'Complete Idiot's ...</td>\n",
       "      <td>joseph yu co author complet idiot guid ching t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>An upgrade for the software has been posted on...</td>\n",
       "      <td>upgrad softwar post onto san websit unlimit ev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>I am also happy to announce the release of the...</td>\n",
       "      <td>also happi announc releas new four pillar feng...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>In case you have missed LiSe's post over at th...</td>\n",
       "      <td>case miss lise post divin discuss section foun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>Thanks to Mick, I actually do have an I Ching ...</td>\n",
       "      <td>thank mick actual ching news snippet start top...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>481 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               content  \\\n",
       "0    Update for 2021Things may be getting back to '...   \n",
       "1    I have uploaded some Imperial China era  chart...   \n",
       "2    Denis Mair has very generously given permissio...   \n",
       "3    Dear all,At last, here is something I promised...   \n",
       "4    Greetings All,    I have  posted a complete ex...   \n",
       "..                                                 ...   \n",
       "476  Joseph Yu, co-author of the 'Complete Idiot's ...   \n",
       "477  An upgrade for the software has been posted on...   \n",
       "478  I am also happy to announce the release of the...   \n",
       "479  In case you have missed LiSe's post over at th...   \n",
       "480  Thanks to Mick, I actually do have an I Ching ...   \n",
       "\n",
       "                                         clean_content  \n",
       "0    updat thing may get back normal extent would s...  \n",
       "1    upload imperi china era chart contempl ching w...  \n",
       "2    deni mair gener given permiss host yije articl...  \n",
       "3    dear last someth promis long time ago seem fin...  \n",
       "4    greet post complet explan king wen sequenc chi...  \n",
       "..                                                 ...  \n",
       "476  joseph yu co author complet idiot guid ching t...  \n",
       "477  upgrad softwar post onto san websit unlimit ev...  \n",
       "478  also happi announc releas new four pillar feng...  \n",
       "479  case miss lise post divin discuss section foun...  \n",
       "480  thank mick actual ching news snippet start top...  \n",
       "\n",
       "[481 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_docs = documents.clean_content.str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      [updat, thing, may, get, back, normal, extent,...\n",
       "1      [upload, imperi, china, era, chart, contempl, ...\n",
       "2      [deni, mair, gener, given, permiss, host, yije...\n",
       "3      [dear, last, someth, promis, long, time, ago, ...\n",
       "4      [greet, post, complet, explan, king, wen, sequ...\n",
       "                             ...                        \n",
       "476    [joseph, yu, co, author, complet, idiot, guid,...\n",
       "477    [upgrad, softwar, post, onto, san, websit, unl...\n",
       "478    [also, happi, announc, releas, new, four, pill...\n",
       "479    [case, miss, lise, post, divin, discuss, secti...\n",
       "480    [thank, mick, actual, ching, news, snippet, st...\n",
       "Name: clean_content, Length: 481, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary=gensim.corpora.Dictionary(processed_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 advanc\n",
      "1 ago\n",
      "2 alon\n",
      "3 alway\n",
      "4 anoth\n",
      "5 april\n",
      "6 avail\n",
      "7 away\n",
      "8 back\n",
      "9 barrier\n",
      "10 beauti\n",
      "11 better\n",
      "12 beyond\n",
      "13 call\n",
      "14 cc\n",
      "15 chanc\n",
      "16 chang\n",
      "17 chat\n",
      "18 chatswhat\n",
      "19 circl\n",
      "20 clariti\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "for k,v in dictionary.iteritems():\n",
    "    print(k,v)\n",
    "    count+=1\n",
    "    if count>20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary.filter_extremes(no_below=15,no_above=0.1,keep_n=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "382"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'event'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary[381]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_corpus=[dictionary.doc2bow(doc) for doc in processed_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "481"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bow_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(10, 1),\n",
       " (34, 1),\n",
       " (38, 1),\n",
       " (97, 1),\n",
       " (129, 1),\n",
       " (131, 1),\n",
       " (161, 1),\n",
       " (167, 1),\n",
       " (217, 1),\n",
       " (229, 1),\n",
       " (237, 1),\n",
       " (259, 1),\n",
       " (284, 1),\n",
       " (299, 1),\n",
       " (301, 1),\n",
       " (303, 1),\n",
       " (318, 1),\n",
       " (320, 1),\n",
       " (325, 1),\n",
       " (333, 1),\n",
       " (336, 1),\n",
       " (339, 2),\n",
       " (343, 1),\n",
       " (375, 1)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_corpus[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 10 (\"clariti\") appears 1 time.\n",
      "Word 34 (\"need\") appears 1 time.\n",
      "Word 38 (\"pm\") appears 1 time.\n",
      "Word 97 (\"mention\") appears 1 time.\n",
      "Word 129 (\"though\") appears 1 time.\n",
      "Word 131 (\"true\") appears 1 time.\n",
      "Word 161 (\"insight\") appears 1 time.\n",
      "Word 167 (\"might\") appears 1 time.\n",
      "Word 217 (\"abl\") appears 1 time.\n",
      "Word 229 (\"short\") appears 1 time.\n",
      "Word 237 (\"pdf\") appears 1 time.\n",
      "Word 259 (\"recommend\") appears 1 time.\n",
      "Word 284 (\"knowledg\") appears 1 time.\n",
      "Word 299 (\"real\") appears 1 time.\n",
      "Word 301 (\"discov\") appears 1 time.\n",
      "Word 303 (\"mayb\") appears 1 time.\n",
      "Word 318 (\"univers\") appears 1 time.\n",
      "Word 320 (\"zhouyi\") appears 1 time.\n",
      "Word 325 (\"richard\") appears 1 time.\n",
      "Word 333 (\"four\") appears 1 time.\n",
      "Word 336 (\"integr\") appears 1 time.\n",
      "Word 339 (\"whole\") appears 2 time.\n",
      "Word 343 (\"appear\") appears 1 time.\n",
      "Word 375 (\"respons\") appears 1 time.\n"
     ]
    }
   ],
   "source": [
    "bow_corpus_100=bow_corpus[100]\n",
    "for i in range(len(bow_corpus_100)):\n",
    "    print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_corpus_100[i][0], \n",
    "                                                     dictionary[bow_corpus_100[i][0]], \n",
    "                                                     bow_corpus_100[i][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora,models\n",
    "tfidf=models.TfidfModel(bow_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_tfidf=tfidf[bow_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(10, 0.18407380904118528),\n",
       " (34, 0.14539480166634217),\n",
       " (38, 0.21470310831665093),\n",
       " (97, 0.20727251352203635),\n",
       " (129, 0.17718473808178276),\n",
       " (131, 0.21877465899917883),\n",
       " (161, 0.17504598616384456),\n",
       " (167, 0.15849417522621084),\n",
       " (217, 0.17939854906799713),\n",
       " (229, 0.19754758808835698),\n",
       " (237, 0.1601328943590641),\n",
       " (259, 0.18654813164098707),\n",
       " (284, 0.21470310831665093),\n",
       " (299, 0.21087847434636606),\n",
       " (301, 0.20386156719439844),\n",
       " (303, 0.20727251352203635),\n",
       " (318, 0.1946127733750525),\n",
       " (320, 0.17097443548131658),\n",
       " (325, 0.18912347450167646),\n",
       " (333, 0.1918084388312061),\n",
       " (336, 0.21087847434636606),\n",
       " (339, 0.37309626328197415),\n",
       " (343, 0.20727251352203635),\n",
       " (375, 0.21877465899917883)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_tfidf[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf, \n",
    "                                             num_topics=10, \n",
    "                                             id2word = dictionary, \n",
    "                                             passes = 2, \n",
    "                                             workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-6.823824582818779"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model_tfidf.log_perplexity(bow_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 Word: 0.018*\"pdf\" + 0.014*\"download\" + 0.010*\"though\" + 0.009*\"list\" + 0.009*\"number\" + 0.009*\"softwar\" + 0.008*\"lot\" + 0.008*\"studi\" + 0.008*\"blog\" + 0.008*\"file\"\n",
      "\n",
      "\n",
      "Topic: 1 Word: 0.017*\"heaven\" + 0.011*\"org\" + 0.010*\"word\" + 0.009*\"back\" + 0.009*\"came\" + 0.009*\"imag\" + 0.009*\"commentari\" + 0.008*\"realli\" + 0.008*\"publish\" + 0.008*\"hi\"\n",
      "\n",
      "\n",
      "Topic: 2 Word: 0.012*\"learn\" + 0.011*\"e\" + 0.011*\"order\" + 0.011*\"titl\" + 0.010*\"n\" + 0.010*\"thank\" + 0.009*\"search\" + 0.008*\"app\" + 0.008*\"friend\" + 0.008*\"regard\"\n",
      "\n",
      "\n",
      "Topic: 3 Word: 0.023*\"wilhelm\" + 0.018*\"amazon\" + 0.012*\"sequenc\" + 0.011*\"print\" + 0.010*\"html\" + 0.010*\"wen\" + 0.009*\"download\" + 0.009*\"ich\" + 0.009*\"friend\" + 0.008*\"pdf\"\n",
      "\n",
      "\n",
      "Topic: 4 Word: 0.015*\"bow\" + 0.015*\"yin\" + 0.014*\"steve\" + 0.014*\"info\" + 0.013*\"yang\" + 0.013*\"blog\" + 0.013*\"updat\" + 0.012*\"part\" + 0.011*\"consult\" + 0.011*\"bit\"\n",
      "\n",
      "\n",
      "Topic: 5 Word: 0.014*\"classic\" + 0.013*\"review\" + 0.012*\"softwar\" + 0.012*\"zhouyi\" + 0.011*\"anoth\" + 0.010*\"journal\" + 0.009*\"news\" + 0.009*\"coin\" + 0.008*\"method\" + 0.008*\"day\"\n",
      "\n",
      "\n",
      "Topic: 6 Word: 0.029*\"edu\" + 0.025*\"cn\" + 0.024*\"zhouyi\" + 0.018*\"china\" + 0.018*\"english\" + 0.011*\"amazon\" + 0.010*\"news\" + 0.010*\"today\" + 0.009*\"th\" + 0.009*\"download\"\n",
      "\n",
      "\n",
      "Topic: 7 Word: 0.016*\"youtub\" + 0.016*\"workshop\" + 0.013*\"jing\" + 0.010*\"harmen\" + 0.009*\"offer\" + 0.009*\"gua\" + 0.008*\"day\" + 0.008*\"app\" + 0.008*\"watch\" + 0.008*\"video\"\n",
      "\n",
      "\n",
      "Topic: 8 Word: 0.019*\"htm\" + 0.016*\"steve\" + 0.015*\"marshal\" + 0.013*\"seen\" + 0.013*\"download\" + 0.011*\"ich\" + 0.011*\"entri\" + 0.010*\"system\" + 0.009*\"languag\" + 0.008*\"journal\"\n",
      "\n",
      "\n",
      "Topic: 9 Word: 0.012*\"amazon\" + 0.010*\"follow\" + 0.010*\"ancient\" + 0.009*\"move\" + 0.008*\"softwar\" + 0.008*\"great\" + 0.008*\"contact\" + 0.008*\"member\" + 0.008*\"meet\" + 0.008*\"share\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in lda_model_tfidf.print_topics(-1):\n",
    "    print(\"Topic: {} Word: {}\".format(idx, topic))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = lda_model_tfidf[corpus_tfidf[100]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.5458807),\n",
       " (1, 0.01726142),\n",
       " (2, 0.017259847),\n",
       " (3, 0.017258957),\n",
       " (4, 0.017252551),\n",
       " (5, 0.01726298),\n",
       " (6, 0.017278709),\n",
       " (7, 0.21670112),\n",
       " (8, 0.017253652),\n",
       " (9, 0.11659005)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 7, 9]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[l[0] for l in a if l[1]>0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.sort(key=lambda x: x[1],reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.5458807),\n",
       " (7, 0.21670112),\n",
       " (9, 0.11659005),\n",
       " (6, 0.017278709),\n",
       " (5, 0.01726298),\n",
       " (1, 0.01726142),\n",
       " (2, 0.017259847),\n",
       " (3, 0.017258957),\n",
       " (8, 0.017253652),\n",
       " (4, 0.017252551)]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.5458807)]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(filter(lambda l:l[1]>0.25, a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "481"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic=[]\n",
    "for i in range(len(corpus_tfidf)):\n",
    "    a = lda_model_tfidf[corpus_tfidf[100]]\n",
    "    a.sort(key=lambda x: x[1],reverse=True)\n",
    "    topic.append([l[0] for l in a if l[1]>0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = []\n",
    "for t in topic:\n",
    "    T.extend(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "481"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T.count(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0 have 481 times\n",
      "Topic 1 have 3 times\n",
      "Topic 2 have 58 times\n",
      "Topic 6 have 21 times\n",
      "Topic 7 have 457 times\n",
      "Topic 9 have 342 times\n"
     ]
    }
   ],
   "source": [
    "for i in set(T):\n",
    "    print(f'Topic {i} have {T.count(i)} times')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
